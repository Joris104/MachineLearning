{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d0d9f32e",
   "metadata": {},
   "source": [
    "# Getting Started Notebook: Stage 2\n",
    "\n",
    "This notebook illustrates how to use the datasets provided to you and will be required to submit your first model.\n",
    "This notebook follows the same structure as the stage 1 notebook, but you will need to perform some additional steps such as feature extraction.\n",
    "\n",
    "## 0. Dependencies\n",
    "\n",
    "This notebook requires several Python **3** packages, which are included in Anaconda 3 for Python 3.8, which is the python distribution we recommend you to use throughout this course.\n",
    "The package versions listed below have been used for testing and are confirmed to work well.\n",
    "We strongly recommend you to install these specific versions to ensure this notebook works as expected and we can offer you optimal support throughout the competition.\n",
    "\n",
    "python: 3.8\n",
    "\n",
    "scikit-learn: 1.0.0\n",
    "\n",
    "numpy: 1.20.1\n",
    "\n",
    "matplotlib: 3.4.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9dbb7f12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn==1.0.0 in ./.venv/lib/python3.8/site-packages (1.0)\n",
      "Requirement already satisfied: numpy in ./.venv/lib/python3.8/site-packages (1.21.2)\n",
      "Requirement already satisfied: matplotlib in ./.venv/lib/python3.8/site-packages (3.4.3)\n",
      "Requirement already satisfied: scipy>=1.1.0 in ./.venv/lib/python3.8/site-packages (from scikit-learn==1.0.0) (1.7.1)\n",
      "Requirement already satisfied: joblib>=0.11 in ./.venv/lib/python3.8/site-packages (from scikit-learn==1.0.0) (1.1.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in ./.venv/lib/python3.8/site-packages (from scikit-learn==1.0.0) (3.0.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in ./.venv/lib/python3.8/site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: pillow>=6.2.0 in ./.venv/lib/python3.8/site-packages (from matplotlib) (8.3.2)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in ./.venv/lib/python3.8/site-packages (from matplotlib) (1.3.2)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in ./.venv/lib/python3.8/site-packages (from matplotlib) (2.4.7)\n",
      "Requirement already satisfied: cycler>=0.10 in ./.venv/lib/python3.8/site-packages (from matplotlib) (0.10.0)\n",
      "Requirement already satisfied: six>=1.5 in ./.venv/lib/python3.8/site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit-learn==1.0.0 numpy matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff07ee7c",
   "metadata": {},
   "source": [
    "## 1. How to use this Notebook\n",
    "\n",
    "This Notebook is based on the stage 1 notebook and provides a sample structure to load data, extract features, and train and tune a scikit-learn pipeline for stage 2.\n",
    "You are not required to follow this exact structure.\n",
    "After you have completed all necessary steps, this notebook will generate a CSV (.csv) file to be submitted on the [Kaggle competition page](https://www.kaggle.com/c/ugentml21-slc-2/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2912c30f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your data, used to name the output file\n",
    "student_id = \"02010068\"\n",
    "student_lastname = \"Dagrain\" \n",
    "student_firstname = \"Miguel\"\n",
    "\n",
    "# change this if you would like your submission outputfile to have a more detailed name, e.g. submission_with_special_preprocessing \n",
    "submission_prefix='submission'\n",
    "\n",
    "# whether or not you want your created models and submissions versioned using timestamps\n",
    "# (setting this to False will overwrite previously exported model and submission files of the same name)\n",
    "use_timestamps = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b7978f6",
   "metadata": {},
   "source": [
    "## 2. Loading the data\n",
    "\n",
    "The dataset contains videos of people signing in Flemish sign language (Vlaamse Gebarentaal). It consists of 15 classes corresponding to lexical signs. From these videos, 3D keypoints were extracted using MediaPipe Holistic. In total, there are 125 keypoints, resulting in 375 (=3x125) floating point values per video frame.\n",
    "\n",
    "In this stage, we expect that you perform your own feature engineering. As a baseline, you can start by extracting the same set of features as we did for stage 1.\n",
    "You can then compare this and future models with the baseline on the Kaggle competition page.\n",
    "\n",
    "As a reminder: the set of features in stage 1 were the time averages of all keypoint coordinates over the first and the second half of the sample frames, so 750 features in total."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24869b00",
   "metadata": {},
   "source": [
    "We start by importing the libraries we need: \n",
    "- sklearn and numpy to do machine learning, \n",
    "- csv and pickle read the data and write out submission and model files, \n",
    "- time and os to keep organized with the files we output,\n",
    "- matplotlib to perform visualizations.\n",
    "We also import some specific sklearn components as well as an utils library with some handy extra functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d7d4cdda",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "import numpy as np\n",
    "import csv\n",
    "import pickle\n",
    "import time\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import StratifiedGroupKFold, GridSearchCV\n",
    "\n",
    "from utils_general import utils_for_students"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b672966",
   "metadata": {},
   "source": [
    "We can use our utils_for_students library to load the data from disk. Remember to put the [unzipped files from the competition page](https://www.kaggle.com/c/ugentml21-slc-2/data) into the right paths on your filesystem.\n",
    "\n",
    "**Note: stage 2 uses different data files than stage 1!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "323196eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_samples = utils_for_students.load_dataset_stage2('data/stage2_labels_train.csv', 'train')\n",
    "test_samples = utils_for_students.load_dataset_stage2('data/stage2_ids_test.csv', 'test')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9438f2e2",
   "metadata": {},
   "source": [
    "For the train data, we get a list of python dictionaries, where each dictionary corresponds to one sign language clip. The dictionary has the following keys:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "93f899e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['path', 'id', 'label', 'signer'])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_samples[0].keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18fcdcb1",
   "metadata": {},
   "source": [
    "For the test data, we also get a list of python dictionaries, but with fewer keys:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "86e33a2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['path', 'id'])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_samples[0].keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "170c7cd7",
   "metadata": {},
   "source": [
    "You can load an individual sample using the provided code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2168b39b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = train_samples[0]\n",
    "\n",
    "landmark_sequence = utils_for_students.load_sample_stage2(os.path.join('data/stage2/train/', sample['path']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbd39f49",
   "metadata": {},
   "source": [
    "We can use the utility code to create a visualization of individual video frames of every sign instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "feb5524e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "FRAME_INDEX = 0\n",
    "\n",
    "utils_for_students.visualize_pose(landmark_sequence[FRAME_INDEX], plt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86032d07",
   "metadata": {},
   "source": [
    "In order to get a better grasp of every class in the dataset, we provide some additional information here.\n",
    "\n",
    "There are 15 different classes. Each class corresponds to a sign. Signs can be annotated using sign glosses, which are representations of signs in written form in a spoken language. In the below table, we list all glosses, the English meaning of the corresponding sign, and provide a link to the Flemish sign language dictionary so that you can see an example performance of that sign.\n",
    "\n",
    "| Gloss             | English meaning | Dictionary URL                                                                                        |\n",
    "|-------------------|-----------------|-------------------------------------------------------------------------------------------------------|\n",
    "| c.AF              | Done, finished  | https://vlaamsegebarentaal.be/signbank/dictionary/protected_media/glossvideo/AF/AF-B-209.mp4          |\n",
    "| c.OOK             | Too, also       | https://vlaamsegebarentaal.be/signbank/dictionary/protected_media/glossvideo/OO/OOK-A-8491.mp4        |\n",
    "| ZELFDE-A          | The same        | https://vlaamsegebarentaal.be/signbank/dictionary/protected_media/glossvideo/ZE/ZELFDE-A-14290.mp4    |\n",
    "| AUTO-RIJDEN-A     | To drive a car  | https://vlaamsegebarentaal.be/signbank/dictionary/protected_media/glossvideo/RI/RIJDEN-C-9982.mp4     |\n",
    "| HEBBEN-A          | To have         | https://vlaamsegebarentaal.be/signbank/dictionary/protected_media/glossvideo/HE/HEBBEN-A-4801.mp4     |\n",
    "| HAAS-oor          | Hare            | https://vlaamsegebarentaal.be/signbank/dictionary/protected_media/glossvideo/HA/HAAS-B-16147.mp4      |\n",
    "| AANKOMEN-A        | To arrive       | https://vlaamsegebarentaal.be/signbank/dictionary/protected_media/glossvideo/AA/AANKOMEN-A-39.mp4     |\n",
    "| SCHILDPAD-Bhanden | Turtle          | https://vlaamsegebarentaal.be/signbank/dictionary/protected_media/glossvideo/SC/SCHILDPAD-A-10503.mp4 |\n",
    "| WAT-A             | What            | https://vlaamsegebarentaal.be/signbank/dictionary/protected_media/glossvideo/WA/WAT-A-13657.mp4       |\n",
    "| c.ZIEN            | To see          | https://vlaamsegebarentaal.be/signbank/dictionary/protected_media/glossvideo/BE/BEKIJKEN-A-1157.mp4   |\n",
    "| NAAR-A            | Towards         | https://vlaamsegebarentaal.be/signbank/dictionary/protected_media/glossvideo/GA/GA-NAAR-A-4032.mp4    |\n",
    "| MOETEN-A          | To must         | https://vlaamsegebarentaal.be/signbank/dictionary/protected_media/glossvideo/MO/MOETEN-D-17652.mp4    |\n",
    "| C: 1              | 1               | https://vlaamsegebarentaal.be/signbank/dictionary/protected_media/glossvideo/1-/1-A-15277.mp4         |\n",
    "| GOED-A            | Good            | https://vlaamsegebarentaal.be/signbank/dictionary/protected_media/glossvideo/GO/GOED-C-4413.mp4       |\n",
    "| C: 2              | 2               | https://vlaamsegebarentaal.be/signbank/dictionary/protected_media/glossvideo/2-/2-A-15278.mp4         |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b464ef9f",
   "metadata": {},
   "source": [
    "## 3. Feature Extraction\n",
    "\n",
    "For stage 1, we performed feature extraction for you.\n",
    "\n",
    "In this stage, you will need to perform feature extraction yourself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b30719fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from frame_avg import extract_features\n",
    "#from sklearn.preprocessing import normalize\n",
    "from utils_feature_preprocessing.split_features_into_frames import split_features_into_frames\n",
    "\n",
    "def extract_features(pose_sequence):\n",
    "    return split_features_into_frames(pose_sequence, k=2)\n",
    "# def extract_features(pose_sequence):\n",
    "#     NUM_SLICES = 2 #TODO : inspect how performance changes with more slices\n",
    "#     size = len(pose_sequence[0])*len(pose_sequence[0][0]) # number of keypoints * number of values per keypoint\n",
    "#     pose_sequence = split_features_into_frames(pose_sequence, NUM_SLICES)\n",
    "#     poses = np.array_split(pose_sequence,NUM_SLICES) #some of these may be empty\n",
    "# #     poses_normalized = []\n",
    "# #     for pose in poses:\n",
    "# #         pose_sorted = pose.reshape(int(pose.shape[0]/3), 3)\n",
    "# #         pose_sorted = pose_sorted - pose_sorted.mean(axis=0)\n",
    "# #         #pose_sorted_normalized = sklearn.preprocessing.normalize(pose_sorted)\n",
    "# #         pose = pose_sorted.flatten()\n",
    "# #         poses_normalized.append(pose)\n",
    "#     #poses_normalized = sklearn.preprocessing.normalize(poses_normalized)\n",
    "#     features = poses[0] #save the initial position\n",
    "#     #here you cut to much information, in the middle of the video we are not necessarily on the same position\n",
    "#     for i in range(1, NUM_SLICES):\n",
    "#         vector = poses[i] - poses[i-1]\n",
    "#         features  = np.append(features, vector)\n",
    "#     return features\n",
    "#     #return np.array(poses_normalized).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fa66aebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils_feature_preprocessing.correct_zero_values import correct_zeros\n",
    "# Concatenate the training set features.\n",
    "X_train = []\n",
    "y_train = []\n",
    "signers_train = []\n",
    "for sample in train_samples:\n",
    "    pose_sequence = utils_for_students.load_sample_stage2(os.path.join('data/stage2/train/', sample['path']))\n",
    "    pose_sequence = correct_zeros(pose_sequence)\n",
    "    X_train.append(extract_features(pose_sequence))\n",
    "    y_train.append(sample['label'])\n",
    "    signers_train.append(sample['signer'])\n",
    "    \n",
    "# Concatenate the test set features.\n",
    "X_test = []\n",
    "test_ids = []\n",
    "for sample in test_samples:\n",
    "    pose_sequence = utils_for_students.load_sample_stage2(os.path.join('data/stage2/test/', sample['path']))\n",
    "    pose_sequence = correct_zeros(pose_sequence)\n",
    "    X_test.append(extract_features(pose_sequence))\n",
    "    test_ids.append(sample['id'])\n",
    "\n",
    "#Combining to numpy array\n",
    "X_train = np.stack(X_train)\n",
    "X_test = np.stack(X_test)\n",
    "\n",
    "# Encode the labels as integers\n",
    "label_encoder = utils_for_students.label_encoder()\n",
    "y_train = label_encoder.transform(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "50444d0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2191, 750)\n",
      "(541, 750)\n",
      "[ 5.91577282e-01  3.78286968e-01 -2.86928013e-01  6.03643487e-01\n",
      "  3.46427446e-01 -2.58362256e-01  6.10377789e-01  3.47145076e-01\n",
      " -2.58760711e-01  6.17259234e-01  3.47173274e-01 -2.58759312e-01\n",
      "  5.82812428e-01  3.45205933e-01 -2.62428480e-01  5.76285193e-01\n",
      "  3.44554747e-01 -2.62777999e-01  5.70241481e-01  3.43811611e-01\n",
      " -2.63034711e-01  6.27112011e-01  3.53380963e-01 -9.19988013e-02\n",
      "  5.63872258e-01  3.51935064e-01 -1.09662503e-01  6.06627146e-01\n",
      "  4.06948984e-01 -2.19758605e-01  5.82404792e-01  4.04490660e-01\n",
      " -2.27568862e-01  6.65919234e-01  5.14250706e-01  9.42027379e-03\n",
      "  5.16301920e-01  5.04570842e-01 -6.29098974e-02  7.05310414e-01\n",
      "  7.50590682e-01 -8.58137080e-02  5.44967661e-01  7.47737060e-01\n",
      " -2.57351602e-01  5.94993909e-01  7.59710014e-01 -3.54945322e-01\n",
      "  6.19667431e-01  5.40412545e-01 -5.42192280e-01  5.67901512e-01\n",
      "  7.63972978e-01 -4.10544410e-01  6.50521199e-01  4.99925216e-01\n",
      " -6.24869655e-01  5.62727243e-01  7.41009136e-01 -4.11703030e-01\n",
      "  6.41804953e-01  4.68531594e-01 -6.05181098e-01  5.70979118e-01\n",
      "  7.40755598e-01 -3.58120690e-01  6.32731199e-01  4.86443813e-01\n",
      " -5.42564124e-01  5.88259727e-01  3.99179166e-01 -6.83039504e-03\n",
      "  5.89434842e-01  4.04520541e-01 -3.56603720e-03  5.89702487e-01\n",
      "  4.07288199e-01 -2.66970702e-03  5.90216617e-01  4.17104011e-01\n",
      " -2.16437226e-03  5.84590187e-01  3.98627987e-01 -5.60220455e-03\n",
      "  5.81480672e-01  4.00285775e-01 -2.72032498e-03  5.79830577e-01\n",
      "  4.02343988e-01  6.17286758e-04  5.61279058e-01  3.36907883e-01\n",
      "  4.86551768e-03  5.66737761e-01  3.31667900e-01 -2.91593062e-03\n",
      "  5.63217272e-01  3.33199094e-01  7.09601220e-04  5.79230318e-01\n",
      "  3.36198375e-01 -7.95372739e-03  5.78358889e-01  4.05672605e-01\n",
      "  7.45396037e-03  5.61737518e-01  3.29307487e-01  2.13690857e-03\n",
      "  5.71951489e-01  3.32466458e-01 -5.87136027e-03  5.71047316e-01\n",
      "  3.27740545e-01 -6.90395463e-03  5.59849898e-01  3.34271630e-01\n",
      "  7.61215459e-03  5.80273896e-01  4.05011659e-01  6.03681112e-03\n",
      "  5.82899888e-01  4.04498657e-01  1.60156658e-03  5.84595641e-01\n",
      "  4.04574965e-01 -5.37653551e-04  5.86763471e-01  4.04668232e-01\n",
      " -2.42328407e-03  5.86452574e-01  4.16736136e-01 -1.11730475e-03\n",
      "  5.86795052e-01  4.07366912e-01 -1.45472872e-03  5.82730502e-01\n",
      "  4.06589776e-01  2.40833533e-03  5.81084728e-01  4.11396911e-01\n",
      "  2.96981889e-03  5.81658036e-01  4.06161636e-01  4.65172413e-03\n",
      "  5.65553168e-01  3.26981296e-01 -2.60130551e-03  5.77662816e-01\n",
      "  3.29043572e-01 -9.78335614e-03  5.79587420e-01  4.08356587e-01\n",
      "  5.53555802e-03  5.84477683e-01  4.07050038e-01  3.89441103e-04\n",
      "  5.83385020e-01  4.14775843e-01  9.40639026e-04  5.78763048e-01\n",
      "  4.03825561e-01  4.16999039e-03  5.81543952e-01  4.04344330e-01\n",
      "  4.13619921e-03  5.92320989e-01  3.97396833e-01 -7.28728327e-03\n",
      "  5.97197076e-01  3.97923340e-01 -6.08756859e-03  6.00765874e-01\n",
      "  3.98936604e-01 -4.05963681e-03  6.16259078e-01  3.28830947e-01\n",
      " -6.83006768e-03  6.06619636e-01  3.25639943e-01 -1.09995472e-02\n",
      "  6.11978441e-01  3.26003879e-01 -9.47229999e-03  5.92116237e-01\n",
      "  3.34220807e-01 -1.06110539e-02  6.05312794e-01  4.00946324e-01\n",
      "  1.12345312e-03  6.13967647e-01  3.21400175e-01 -8.75447830e-03\n",
      "  6.00032777e-01  3.28178257e-01 -1.14198347e-02  6.00301494e-01\n",
      "  3.23134447e-01 -1.26180787e-02  6.18799398e-01  3.25324943e-01\n",
      " -4.91930971e-03  6.03479018e-01  4.00934860e-01  6.14879644e-04\n",
      "  5.98813206e-01  4.01605422e-01 -2.20719841e-03  5.95934967e-01\n",
      "  4.02618428e-01 -3.36800958e-03  5.92800697e-01  4.03646514e-01\n",
      " -3.99203540e-03  5.94487856e-01  4.15733625e-01 -2.80576960e-03\n",
      "  5.93178441e-01  4.06486531e-01 -3.06484631e-03  5.99354714e-01\n",
      "  4.03849696e-01 -1.37918876e-03  6.01492395e-01  4.08269823e-01\n",
      " -1.19113516e-03  6.01344615e-01  4.02754972e-01 -7.05249495e-05\n",
      "  6.07622812e-01  3.20432107e-01 -1.11448434e-02  5.92591455e-01\n",
      "  3.26543664e-01 -1.26535109e-02  6.03777558e-01  4.04296006e-01\n",
      "  2.48978362e-04  5.96397718e-01  4.05206536e-01 -2.45143671e-03\n",
      "  5.98296434e-01  4.12634229e-01 -2.26534164e-03  6.03675852e-01\n",
      "  3.99524098e-01 -1.60914044e-03  6.01348609e-01  4.00787140e-01\n",
      " -6.41870451e-04  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  6.07010270e-01  5.27887727e-01  5.47779774e-01  6.08177771e-01\n",
      "  4.91183966e-01  5.53607597e-01  6.16588448e-01  4.62065202e-01\n",
      "  5.53534645e-01  6.27288992e-01  4.50946478e-01  5.51252328e-01\n",
      "  6.36398027e-01  4.51872580e-01  5.49936872e-01  6.30309006e-01\n",
      "  4.39840590e-01  5.50621994e-01  6.43017655e-01  4.09511236e-01\n",
      "  5.47695058e-01  6.50137628e-01  3.98628568e-01  5.46761986e-01\n",
      "  6.54074455e-01  3.93071530e-01  5.46678093e-01  6.39562786e-01\n",
      "  4.50890149e-01  5.45335646e-01  6.55218080e-01  4.48905533e-01\n",
      "  5.44258970e-01  6.53838823e-01  4.60464023e-01  5.46964779e-01\n",
      "  6.48703679e-01  4.67483299e-01  5.49152377e-01  6.45924464e-01\n",
      "  4.68528258e-01  5.40141605e-01  6.56864852e-01  4.73893076e-01\n",
      "  5.40076532e-01  6.52365317e-01  4.82203459e-01  5.43456006e-01\n",
      "  6.46175722e-01  4.85604492e-01  5.45767959e-01  6.50559167e-01\n",
      "  4.88933206e-01  5.34669221e-01  6.57149151e-01  4.95291310e-01\n",
      "  5.35536984e-01  6.52630135e-01  5.01537825e-01  5.37902884e-01\n",
      "  6.46657422e-01  5.04455715e-01  5.39958123e-01  5.95261733e-01\n",
      "  3.78904422e-01 -3.21784779e-01  6.04486793e-01  3.46976548e-01\n",
      " -2.95023059e-01  6.11781468e-01  3.47477486e-01 -2.95440421e-01\n",
      "  6.19259695e-01  3.47476562e-01 -2.95482188e-01  5.84594081e-01\n",
      "  3.45898966e-01 -2.96175251e-01  5.77441504e-01  3.45533088e-01\n",
      " -2.96567063e-01  5.71834534e-01  3.44899933e-01 -2.96839620e-01\n",
      "  6.30285939e-01  3.55619580e-01 -1.30574791e-01  5.63333064e-01\n",
      "  3.52425888e-01 -1.36502991e-01  6.08725399e-01  4.06098326e-01\n",
      " -2.54771476e-01  5.84512432e-01  4.04883444e-01 -2.59014865e-01\n",
      "  6.68072134e-01  5.15191317e-01 -3.89972006e-02  5.17513772e-01\n",
      "  5.04893144e-01 -6.45951964e-02  7.02718675e-01  7.48968015e-01\n",
      " -1.18298904e-01  5.39992164e-01  7.40133534e-01 -2.57030678e-01\n",
      "  5.95962067e-01  7.54513363e-01 -3.58106330e-01  5.98182331e-01\n",
      "  5.33958415e-01 -5.69381863e-01  5.69083432e-01  7.57069558e-01\n",
      " -4.12523568e-01  6.24549031e-01  4.90424027e-01 -6.52254343e-01\n",
      "  5.63233286e-01  7.31962353e-01 -4.15384496e-01  6.14506235e-01\n",
      "  4.62634707e-01 -6.38179074e-01  5.70502510e-01  7.30055938e-01\n",
      " -3.61252328e-01  6.06877188e-01  4.81364409e-01 -5.72773208e-01\n",
      "  5.88451207e-01  3.99955605e-01 -6.42763715e-03  5.89356422e-01\n",
      "  4.04983292e-01 -3.07118117e-03  5.89512875e-01  4.06255806e-01\n",
      " -2.28935794e-03  5.89882404e-01  4.15074721e-01 -2.08398944e-03\n",
      "  5.84772925e-01  3.99274076e-01 -5.42944918e-03  5.81539780e-01\n",
      "  4.00775785e-01 -2.79321820e-03  5.79785575e-01  4.02634492e-01\n",
      "  2.47619861e-04  5.61677674e-01  3.35918958e-01  3.44548440e-03\n",
      "  5.67352047e-01  3.31008072e-01 -3.83233873e-03  5.63749413e-01\n",
      "  3.32447131e-01 -4.79909265e-04  5.80064048e-01  3.35592439e-01\n",
      " -8.18397788e-03  5.78010668e-01  4.05506954e-01  6.66178375e-03\n",
      "  5.62219878e-01  3.28487640e-01  8.63011713e-04  5.72642863e-01\n",
      "  3.31758032e-01 -6.45992602e-03  5.71778119e-01  3.27024281e-01\n",
      " -7.49574990e-03  5.60173402e-01  3.33102569e-01  6.05986795e-03\n",
      "  5.79759657e-01  4.04878890e-01  5.29132636e-03  5.82656304e-01\n",
      "  4.04679080e-01  1.37365959e-03  5.84478329e-01  4.04811184e-01\n",
      " -4.86239531e-04  5.86725831e-01  4.05003125e-01 -2.14228533e-03\n",
      "  5.86239000e-01  4.14746433e-01 -1.28897194e-03  5.86640080e-01\n",
      "  4.06295364e-01 -1.35242242e-03  5.82405945e-01  4.05787677e-01\n",
      "  1.93128343e-03  5.80792040e-01  4.10100644e-01  2.27843782e-03\n",
      "  5.81244498e-01  4.05565043e-01  3.91637844e-03  5.66137105e-01\n",
      "  3.26288179e-01 -3.58489633e-03  5.78604142e-01  3.28397155e-01\n",
      " -1.00267059e-02  5.79235752e-01  4.07641798e-01  4.74683343e-03\n",
      "  5.84258129e-01  4.06047011e-01  1.97231869e-04  5.83162953e-01\n",
      "  4.12991519e-01  4.17729780e-04  5.78557402e-01  4.03980290e-01\n",
      "  3.54947317e-03  5.81160575e-01  4.04495373e-01  3.60872139e-03\n",
      "  5.92465331e-01  3.98391714e-01 -6.70258072e-03  5.97111106e-01\n",
      "  3.99111703e-01 -5.35790832e-03  6.00370874e-01  4.00227398e-01\n",
      " -3.33473773e-03  6.17043217e-01  3.30122789e-01 -5.77480524e-03\n",
      "  6.07920676e-01  3.26442872e-01 -1.02037489e-02  6.13058815e-01\n",
      "  3.27163522e-01 -8.48487827e-03  5.93274007e-01  3.34036946e-01\n",
      " -1.02617140e-02  6.04426265e-01  4.02107378e-01  1.75380499e-03\n",
      "  6.15077287e-01  3.22681939e-01 -7.72869051e-03  6.01372461e-01\n",
      "  3.28436136e-01 -1.08285899e-02  6.01784875e-01  3.23444953e-01\n",
      " -1.19916180e-02  6.19471461e-01  3.26726258e-01 -3.82699903e-03\n",
      "  6.02704078e-01  4.01931291e-01  1.11366002e-03  5.98331094e-01\n",
      "  4.02550767e-01 -1.51227729e-03  5.95602751e-01  4.03399592e-01\n",
      " -2.62956050e-03  5.92563818e-01  4.04268781e-01 -3.31764556e-03\n",
      "  5.93952686e-01  4.14057016e-01 -2.54502008e-03  5.92852900e-01\n",
      "  4.05651743e-01 -2.54346442e-03  5.98765135e-01  4.03786023e-01\n",
      " -9.46443479e-04  6.00715309e-01  4.07882884e-01 -8.84968283e-04\n",
      "  6.00648165e-01  4.03105905e-01  3.05109154e-04  6.09028131e-01\n",
      "  3.21317027e-01 -1.03062629e-02  5.93938271e-01  3.26400409e-01\n",
      " -1.22764704e-02  6.02919519e-01  4.04744898e-01  6.69870220e-04\n",
      "  5.95964839e-01  4.04701432e-01 -1.93894424e-03  5.97628276e-01\n",
      "  4.11476339e-01 -1.97793914e-03  6.03010068e-01  4.00883004e-01\n",
      " -9.14090167e-04  6.00688348e-01  4.01904225e-01 -4.42694994e-05\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  5.97843518e-01\n",
      "  5.16067783e-01  5.69381863e-01  5.96164862e-01  4.78814920e-01\n",
      "  5.77276486e-01  6.01161420e-01  4.49499115e-01  5.78109833e-01\n",
      "  6.10163659e-01  4.36506256e-01  5.76600004e-01  6.18729730e-01\n",
      "  4.34781437e-01  5.75827293e-01  6.07671460e-01  4.26461513e-01\n",
      "  5.73097062e-01  6.14529808e-01  3.90750304e-01  5.70838466e-01\n",
      "  6.20160639e-01  3.68693888e-01  5.70124166e-01  6.23978128e-01\n",
      "  3.53406524e-01  5.69899861e-01  6.15793665e-01  4.35162604e-01\n",
      "  5.66792411e-01  6.35062993e-01  4.21830167e-01  5.65595941e-01\n",
      "  6.35462860e-01  4.33837995e-01  5.68905031e-01  6.30653302e-01\n",
      "  4.44579894e-01  5.71750106e-01  6.22857412e-01  4.51059967e-01\n",
      "  5.60843630e-01  6.38292938e-01  4.47635045e-01  5.60578378e-01\n",
      "  6.35313968e-01  4.57760413e-01  5.65116690e-01  6.29866193e-01\n",
      "  4.63990306e-01  5.68395865e-01  6.28812780e-01  4.70060438e-01\n",
      "  5.54831178e-01  6.39781266e-01  4.67066849e-01  5.55148919e-01\n",
      "  6.36682659e-01  4.74850376e-01  5.58188152e-01  6.31384412e-01\n",
      "  4.80289544e-01  5.60892470e-01]\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(X_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "463e5545",
   "metadata": {},
   "source": [
    "## 4. Creating pipelines for preprocessing and feature selection \n",
    "\n",
    "Now, we are ready to define our pipelines. You can create the same pipeline as for stage 1 as a baseline, but you will be expected to tune both the feature engineering\n",
    "and pipeline parts of your model iteratively to improve your results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e7f2dafb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, Normalizer\n",
    "from sklearn.feature_selection import SelectFwe, SelectFromModel, SelectKBest, f_classif, chi2, mutual_info_classif\n",
    "from sklearn.linear_model import RidgeClassifier, LogisticRegression\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "#chosen PCA instead of LDA as the n_components of LDA has to be <= min(n_classes - 1, n_features) which is 14 in\n",
    "#this case (down from 750). Which is likely to little given the that the features are only x, y or z values.\n",
    "preprocessing = Pipeline([\n",
    "     ('normalizer', Normalizer()),\n",
    "     ('scaler', MinMaxScaler()),\n",
    "     ('decompose', PCA()),\n",
    "     ('rescale', MinMaxScaler()),\n",
    "                        ]) \n",
    "\n",
    "#TODO: define feature selection pipeline here\n",
    "#first we remove the features that mithingsght lead to false results\n",
    "#then we use selectFromModel to assign weights and take the least important features away for generalization\n",
    "#ofcourse only using linear regression models (the same model as the actual classifier)\n",
    "feature_selection = Pipeline([\n",
    "    #('selectFromModel', SelectFromModel(RidgeClassifier(fit_intercept=False))),\n",
    "    ('selectKBest', SelectKBest()),\n",
    "                            ]) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f34eda7d",
   "metadata": {},
   "source": [
    "## 5. Define a suitable classifier\n",
    "With your preprocessing and feature selection in place, it is now time to define the final element: a suitable classifier. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ffcf7c1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: define proper classifier\n",
    "classifier = RidgeClassifier(fit_intercept=False, class_weight=\"balanced\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9e79000",
   "metadata": {},
   "source": [
    "## 6. Set up hyperparameter grid for [GridsearchCV](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html?highlight=gridsearchcv#sklearn.model_selection.GridSearchCV) object.\n",
    "\n",
    "Now, define your GridSearchCV hyperparameter grid and object.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7b76a42e",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'preprocessing__decompose__n_components':[180],#[\"mle\", None, 50,100,110,120,130,140,150,180,190,200,210,220,250,300,350,400,450,500,550,600,650,700,750],\n",
    "    'feature_selection__selectKBest__score_func': [f_classif],# mutual_info_classif],\n",
    "    'feature_selection__selectKBest__k': [180],#[50,100,110,120,130,140,150,180,190,200,210,220,250,300,350,400,450,500,550,600,650,700,750],\n",
    "    'classifier__alpha': [1],#[1e9, 1e8, 1e7, 1e6, 1e5, 1e4, 1e3, 1e2, 1],\n",
    "    'classifier__tol': [1.0e-5],#[1.0e-5, 1.0e-4,  1.0e-2, 1.0e-1, 0.2, 0.5, 0.7, 0.9]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c846167",
   "metadata": {},
   "source": [
    "## 7. Define the number of crossvaldation folds and how to split\n",
    "\n",
    "Now, you should define the number of CV folds and how to split the data.\n",
    "Assuming you had a correct split in the first stage of the competition, you can re-use the same code.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "79933468",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_folds = 4\n",
    "\n",
    "# The function below is just an example!\n",
    "#TODO: write a better split function here?\n",
    "#split according to signer for i.i.d. sets\n",
    "def create_folds(X,y,n_folds):\n",
    "    folds = []\n",
    "    cv_object = StratifiedGroupKFold(n_splits = n_folds)\n",
    "    for (train_indices, val_indices) in  cv_object.split(X_train, y_train, groups=signers_train):\n",
    "        folds.append((train_indices,val_indices))\n",
    "    return folds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61a151ce",
   "metadata": {},
   "source": [
    "## 8. Training the model\n",
    "Now it is time to put everything together and train the model. As you can see, `GridsearchCV` takes the pipelines as well as the classifier and the hyperparameter dictionary you defined, and uses `create_folds` to create list of train and test indices for each split. Then the model is trained using `cv.fit()` and the model and submission files are written to the file system.\n",
    "\n",
    "In stage 2, this cell is no longer locked and you are free to edit it as you like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d086e92c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=[(array([   0,    1,    2, ..., 2187, 2189, 2190]),\n",
       "                  array([   4,    6,   12,   13,   16,   21,   29,   43,   49,   58,   60,\n",
       "         65,   70,   73,   74,   81,   85,   86,   89,   91,   92,  100,\n",
       "        102,  103,  104,  105,  107,  109,  121,  122,  124,  126,  127,\n",
       "        130,  150,  154,  159,  163,  164,  170,  172,  178,  181,  182,\n",
       "        199,  204,  207,  208,  209,  212,  213,  220,  222,  226,  229,\n",
       "        237,  242,  246,  253,  254,  264,  267,  275,  278,  279,  283,\n",
       "        284,  290,  299,  300,  305,  309,  313,  314,  317,  318,  320,\n",
       "        322,  32...\n",
       "                                       ('classifier',\n",
       "                                        RidgeClassifier(class_weight='balanced',\n",
       "                                                        fit_intercept=False))]),\n",
       "             n_jobs=4,\n",
       "             param_grid={'classifier__alpha': [1], 'classifier__tol': [1e-05],\n",
       "                         'feature_selection__selectKBest__k': [180],\n",
       "                         'feature_selection__selectKBest__score_func': [<function f_classif at 0x7f993b27a700>],\n",
       "                         'preprocessing__decompose__n_components': [180]},\n",
       "             return_train_score=True, verbose=1)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('preprocessing', preprocessing),\n",
    "    ('feature_selection', feature_selection),\n",
    "    ('classifier', classifier)])\n",
    "\n",
    "folds = create_folds(X_train,y_train,n_folds)\n",
    "assert isinstance(folds,list),'Folds must be presented as tuples of train and test index lists' \n",
    "\n",
    "# train model\n",
    "cv = GridSearchCV(pipeline, param_grid, n_jobs=4, cv=folds, verbose=1, return_train_score=True, refit=True)\n",
    "cv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5b03ad18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write out model\n",
    "#make sure student data is filled in to give the file a speaking name\n",
    "assert student_id is not None and student_lastname is not None and student_firstname is not None, 'Please fill in your Name and Student Id'\n",
    "\n",
    "submission_dirname = 'submission'\n",
    "if use_timestamps:\n",
    "    timestamp = time.strftime(\"%Y%m%d-%H%M%S\", time.localtime())\n",
    "    filename_model = os.path.join(submission_dirname,f'stage2_model_{student_id}_{student_lastname}_{student_firstname}_{timestamp}.pkl')\n",
    "    filename_submission =  os.path.join(submission_dirname,f'stage2_{submission_prefix}_{student_id}_{student_lastname}_{student_firstname}_{timestamp}.csv')\n",
    "else:\n",
    "    filename_model = os.path.join(submission_dirname,f'stage2_model_{student_id}_{student_lastname}_{student_firstname}.pkl')\n",
    "    filename_submission =  os.path.join(submission_dirname,f'stage2_{submission_prefix}_{student_id}_{student_lastname}_{student_firstname}.csv')\n",
    "\n",
    "if not os.path.exists(submission_dirname):\n",
    "    os.mkdir(submission_dirname)    \n",
    "\n",
    "with open(filename_model,'wb') as file:\n",
    "    pickle.dump(cv,file)\n",
    "    \n",
    "prediction = label_encoder.inverse_transform(cv.best_estimator_.predict(X_test))\n",
    "utils_for_students.create_submission_file(filename_submission, test_ids, prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ce9c1ec",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 9. Printing scores\n",
    "Here we simply extract a bit more information about the individual scores obtained by the classifers we trained to fit the individual folds. Maybe a few plots may be useful to better understand what your classifier is doing? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a51138df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy 0.8805353588450286 +/- 0.006468086001842357\n",
      "Cross-validation accuracy: 0.6698333303972119 +/- 0.04301891650361757\n",
      "Best estimator:\n",
      "Pipeline(steps=[('preprocessing',\n",
      "                 Pipeline(steps=[('normalizer', Normalizer()),\n",
      "                                 ('scaler', MinMaxScaler()),\n",
      "                                 ('decompose', PCA(n_components=180)),\n",
      "                                 ('rescale', MinMaxScaler())])),\n",
      "                ('feature_selection',\n",
      "                 Pipeline(steps=[('selectKBest', SelectKBest(k=180))])),\n",
      "                ('classifier',\n",
      "                 RidgeClassifier(alpha=1, class_weight='balanced',\n",
      "                                 fit_intercept=False, tol=1e-05))])\n"
     ]
    }
   ],
   "source": [
    "results = cv.cv_results_\n",
    "mean_train_score = results['mean_train_score'][cv.best_index_]\n",
    "std_train_score = results['std_train_score'][cv.best_index_]\n",
    "mean_cv_score = results['mean_test_score'][cv.best_index_]\n",
    "std_cv_score = results['std_test_score'][cv.best_index_]\n",
    "\n",
    "print('Training accuracy {} +/- {}'.format(mean_train_score, std_train_score))\n",
    "print('Cross-validation accuracy: {} +/- {}'.format(mean_cv_score, std_cv_score))\n",
    "\n",
    "print('Best estimator:')\n",
    "print(cv.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c7e19ef6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set found on development set:  {'classifier__alpha': 1, 'classifier__tol': 1e-05, 'feature_selection__selectKBest__k': 180, 'feature_selection__selectKBest__score_func': <function f_classif at 0x7f993b27a700>, 'preprocessing__decompose__n_components': 180}\n",
      "Grid scores on training data set:\n",
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "x and y must have same first dimension, but have shapes (23,) and (1,)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_55590/522411996.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;31m#C_range = [\"f_classif\", \"chi2\"]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mC_range\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_means\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'g-'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"train\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mC_range\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcv_means\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'r-'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"validate\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;31m#plt.plot(np.log10(C_range),train_means,'g-',label=\"train\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/MachineLearning/Competition/MLCompetition/.venv/lib/python3.8/site-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3017\u001b[0m \u001b[0;34m@\u001b[0m\u001b[0m_copy_docstring_and_deprecators\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mAxes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3018\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscalex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscaley\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3019\u001b[0;31m     return gca().plot(\n\u001b[0m\u001b[1;32m   3020\u001b[0m         \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscalex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscalex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscaley\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscaley\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3021\u001b[0m         **({\"data\": data} if data is not None else {}), **kwargs)\n",
      "\u001b[0;32m~/MachineLearning/Competition/MLCompetition/.venv/lib/python3.8/site-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(self, scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1603\u001b[0m         \"\"\"\n\u001b[1;32m   1604\u001b[0m         \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcbook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize_kwargs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmlines\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLine2D\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1605\u001b[0;31m         \u001b[0mlines\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_lines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1606\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlines\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1607\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/MachineLearning/Competition/MLCompetition/.venv/lib/python3.8/site-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m    313\u001b[0m                 \u001b[0mthis\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m                 \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 315\u001b[0;31m             \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_plot_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    316\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_next_color\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/MachineLearning/Competition/MLCompetition/.venv/lib/python3.8/site-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m_plot_args\u001b[0;34m(self, tup, kwargs, return_kwargs)\u001b[0m\n\u001b[1;32m    499\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    500\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 501\u001b[0;31m             raise ValueError(f\"x and y must have same first dimension, but \"\n\u001b[0m\u001b[1;32m    502\u001b[0m                              f\"have shapes {x.shape} and {y.shape}\")\n\u001b[1;32m    503\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: x and y must have same first dimension, but have shapes (23,) and (1,)"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# use for visualizing certain evolutions\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(\"Best parameters set found on development set: \",cv.best_params_)\n",
    "# store the best optimization parameter for later reuse\n",
    "bestC2 = cv.best_params_['classifier__alpha']\n",
    "\n",
    "print(\"Grid scores on training data set:\")\n",
    "print()\n",
    "cv_means = cv.cv_results_['mean_test_score']\n",
    "cv_stds = cv.cv_results_['std_test_score']\n",
    "\n",
    "train_means = cv.cv_results_['mean_train_score']\n",
    "train_stds = cv.cv_results_['std_train_score']\n",
    "\n",
    "#C_range = [0.92, 0.9, 0.8, 0.75, 0.5, 0.2, 1e-1, 5e-2, 2.5e-2]\n",
    "#C_range = [\"0.1*mean\",\"0.15*mean\",\"0.2*mean\",\"0.25*mean\", \"0.75*mean\", \"1*mean\", \"1.2*mean\", \"1.25*mean\", \"1.5*mean\", \"0.2*median\",\"0.3*median\",\"0.4*median\",\"0.5*median\", \"0.75*median\", \"1*median\", \"1.25*median\", \"2*median\", \"2.05*median\", \"2.1*median\", \"2.2*median\"]\n",
    "C_range = [50,100,110,120,130,140,150,180,190,200,210,220,250,300,350,400,450,500,550,600,650,700,750]\n",
    "#C_range = [True, False]\n",
    "#C_range = ['mle', 140, 150, 160, 170, 180, 190, 200, 250, 300, 350, 400, 450, 500, 550, 600, 650, 700, 750]\n",
    "#C_range = [1.0e10, 1.0e9, 1.0e8, 1.0e7, 1.0e6, 1.0e5, 1.0e4, 1.0e3, 1.0e2, 10, 1.0]\n",
    "#C_range = [1.0e-5, 1.0e-4,  1.0e-2, 1.0e-1, 0.2, 0.5, 0.7, 0.9]\n",
    "# C_range = [1.0e-6, 1.0e-4, 1.0e-2, 1.0e-1, 0.2, 0.5, 0.8]\n",
    "#C_range = [1e9, 1e8, 1e7, 1e6, 1e5, 1e4, 1e3, 1e2, 1, 1e-1, 1e-2, 1e-3]\n",
    "#C_range = [1e-2, 2.5e-2, 5e-2, 1e-1, 1.5e-1, 2e-1, 3e-1, 5e-1, 6e-1, 6.5e-1, 7e-1, 9e-1, 9.9e-1, 1]\n",
    "#C_range = [\"f_classif\", \"chi2\"]\n",
    "plt.figure()\n",
    "plt.plot(C_range,train_means,'g-',label=\"train\")\n",
    "plt.plot(C_range,cv_means,'r-',label=\"validate\")\n",
    "#plt.plot(np.log10(C_range),train_means,'g-',label=\"train\")\n",
    "#plt.plot(np.log10(C_range),cv_means,'r-',label=\"validate\")\n",
    "plt.xlabel(\"classifier__C\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "808d23bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62075a47",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5b96519fadf0e27573d7db6a7c141d11ba6990cab00b556a7220b1bf1bdbac7f"
  },
  "kernelspec": {
   "display_name": "Python ML",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
