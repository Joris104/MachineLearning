{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "890a257c",
   "metadata": {},
   "source": [
    "# Getting Started Notebook: Stage 2\n",
    "\n",
    "This notebook illustrates how to use the datasets provided to you and will be required to submit your first model.\n",
    "This notebook follows the same structure as the stage 1 notebook, but you will need to perform some additional steps such as feature extraction.\n",
    "\n",
    "## 0. Dependencies\n",
    "\n",
    "This notebook requires several Python **3** packages, which are included in Anaconda 3 for Python 3.8, which is the python distribution we recommend you to use throughout this course.\n",
    "The package versions listed below have been used for testing and are confirmed to work well.\n",
    "We strongly recommend you to install these specific versions to ensure this notebook works as expected and we can offer you optimal support throughout the competition.\n",
    "\n",
    "python: 3.8\n",
    "\n",
    "scikit-learn: 1.0.0\n",
    "\n",
    "numpy: 1.20.1\n",
    "\n",
    "matplotlib: 3.4.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e500989f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install scikit-learn==1.0.0 numpy matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3c6fc0f",
   "metadata": {},
   "source": [
    "## 1. How to use this Notebook\n",
    "\n",
    "This Notebook is based on the stage 1 notebook and provides a sample structure to load data, extract features, and train and tune a scikit-learn pipeline for stage 2.\n",
    "You are not required to follow this exact structure.\n",
    "After you have completed all necessary steps, this notebook will generate a CSV (.csv) file to be submitted on the [Kaggle competition page](https://www.kaggle.com/c/ugentml21-slc-2/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "346907b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your data, used to name the output file\n",
    "student_id = None\n",
    "student_lastname = None\n",
    "student_firstname = None\n",
    "\n",
    "# change this if you would like your submission outputfile to have a more detailed name, e.g. submission_with_special_preprocessing \n",
    "submission_prefix='submission'\n",
    "\n",
    "# whether or not you want your created models and submissions versioned using timestamps\n",
    "# (setting this to False will overwrite previously exported model and submission files of the same name)\n",
    "use_timestamps = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1afe251",
   "metadata": {},
   "source": [
    "## 2. Loading the data\n",
    "\n",
    "The dataset contains videos of people signing in Flemish sign language (Vlaamse Gebarentaal). It consists of 15 classes corresponding to lexical signs. From these videos, 3D keypoints were extracted using MediaPipe Holistic. In total, there are 125 keypoints, resulting in 375 (=3x125) floating point values per video frame.\n",
    "\n",
    "In this stage, we expect that you perform your own feature engineering. As a baseline, you can start by extracting the same set of features as we did for stage 1.\n",
    "You can then compare this and future models with the baseline on the Kaggle competition page.\n",
    "\n",
    "As a reminder: the set of features in stage 1 were the time averages of all keypoint coordinates over the first and the second half of the sample frames, so 750 features in total."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfe8eb7c",
   "metadata": {},
   "source": [
    "We start by importing the libraries we need: \n",
    "- sklearn and numpy to do machine learning, \n",
    "- csv and pickle read the data and write out submission and model files, \n",
    "- time and os to keep organized with the files we output,\n",
    "- matplotlib to perform visualizations.\n",
    "We also import some specific sklearn components as well as an utils library with some handy extra functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8744151d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "import numpy as np\n",
    "import csv\n",
    "import pickle\n",
    "import time\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import KFold, GridSearchCV\n",
    "\n",
    "import utils_for_students"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80b4b53c",
   "metadata": {},
   "source": [
    "We can use our utils_for_students library to load the data from disk. Remember to put the [unzipped files from the competition page](https://www.kaggle.com/c/ugentml21-slc-2/data) into the right paths on your filesystem.\n",
    "\n",
    "**Note: stage 2 uses different data files than stage 1!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ec1a8f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_samples = utils_for_students.load_dataset_stage2('data/stage2_labels_train.csv', 'train')\n",
    "test_samples = utils_for_students.load_dataset_stage2('data/stage2_ids_test.csv', 'test')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e3245d6",
   "metadata": {},
   "source": [
    "For the train data, we get a list of python dictionaries, where each dictionary corresponds to one sign language clip. The dictionary has the following keys:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29062fb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_samples[0].keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8a37601",
   "metadata": {},
   "source": [
    "For the test data, we also get a list of python dictionaries, but with fewer keys:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a28d57e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_samples[0].keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f99134e7",
   "metadata": {},
   "source": [
    "You can load an individual sample using the provided code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72847fc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = train_samples[0]\n",
    "\n",
    "landmark_sequence = utils_for_students.load_sample_stage2(os.path.join('data/stage2/train/', sample['path']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57ad7773",
   "metadata": {},
   "source": [
    "We can use the utility code to create a visualization of individual video frames of every sign instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7192547a",
   "metadata": {},
   "outputs": [],
   "source": [
    "FRAME_INDEX = 0\n",
    "\n",
    "utils_for_students.visualize_pose(landmark_sequence[FRAME_INDEX], plt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f33f7a01",
   "metadata": {},
   "source": [
    "In order to get a better grasp of every class in the dataset, we provide some additional information here.\n",
    "\n",
    "There are 15 different classes. Each class corresponds to a sign. Signs can be annotated using sign glosses, which are representations of signs in written form in a spoken language. In the below table, we list all glosses, the English meaning of the corresponding sign, and provide a link to the Flemish sign language dictionary so that you can see an example performance of that sign.\n",
    "\n",
    "| Gloss             | English meaning | Dictionary URL                                                                                        |\n",
    "|-------------------|-----------------|-------------------------------------------------------------------------------------------------------|\n",
    "| c.AF              | Done, finished  | https://vlaamsegebarentaal.be/signbank/dictionary/protected_media/glossvideo/AF/AF-B-209.mp4          |\n",
    "| c.OOK             | Too, also       | https://vlaamsegebarentaal.be/signbank/dictionary/protected_media/glossvideo/OO/OOK-A-8491.mp4        |\n",
    "| ZELFDE-A          | The same        | https://vlaamsegebarentaal.be/signbank/dictionary/protected_media/glossvideo/ZE/ZELFDE-A-14290.mp4    |\n",
    "| AUTO-RIJDEN-A     | To drive a car  | https://vlaamsegebarentaal.be/signbank/dictionary/protected_media/glossvideo/RI/RIJDEN-C-9982.mp4     |\n",
    "| HEBBEN-A          | To have         | https://vlaamsegebarentaal.be/signbank/dictionary/protected_media/glossvideo/HE/HEBBEN-A-4801.mp4     |\n",
    "| HAAS-oor          | Hare            | https://vlaamsegebarentaal.be/signbank/dictionary/protected_media/glossvideo/HA/HAAS-B-16147.mp4      |\n",
    "| AANKOMEN-A        | To arrive       | https://vlaamsegebarentaal.be/signbank/dictionary/protected_media/glossvideo/AA/AANKOMEN-A-39.mp4     |\n",
    "| SCHILDPAD-Bhanden | Turtle          | https://vlaamsegebarentaal.be/signbank/dictionary/protected_media/glossvideo/SC/SCHILDPAD-A-10503.mp4 |\n",
    "| WAT-A             | What            | https://vlaamsegebarentaal.be/signbank/dictionary/protected_media/glossvideo/WA/WAT-A-13657.mp4       |\n",
    "| c.ZIEN            | To see          | https://vlaamsegebarentaal.be/signbank/dictionary/protected_media/glossvideo/BE/BEKIJKEN-A-1157.mp4   |\n",
    "| NAAR-A            | Towards         | https://vlaamsegebarentaal.be/signbank/dictionary/protected_media/glossvideo/GA/GA-NAAR-A-4032.mp4    |\n",
    "| MOETEN-A          | To must         | https://vlaamsegebarentaal.be/signbank/dictionary/protected_media/glossvideo/MO/MOETEN-D-17652.mp4    |\n",
    "| C: 1              | 1               | https://vlaamsegebarentaal.be/signbank/dictionary/protected_media/glossvideo/1-/1-A-15277.mp4         |\n",
    "| GOED-A            | Good            | https://vlaamsegebarentaal.be/signbank/dictionary/protected_media/glossvideo/GO/GOED-C-4413.mp4       |\n",
    "| C: 2              | 2               | https://vlaamsegebarentaal.be/signbank/dictionary/protected_media/glossvideo/2-/2-A-15278.mp4         |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45b3495b",
   "metadata": {},
   "source": [
    "## 3. Feature Extraction\n",
    "\n",
    "For stage 1, we performed feature extraction for you.\n",
    "\n",
    "In this stage, you will need to perform feature extraction yourself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d35d4c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(pose_sequence):\n",
    "    # You should implement this function to return better features!\n",
    "    return pose_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c505bbaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate the training set features.\n",
    "X_train = []\n",
    "y_train = []\n",
    "signers_train = []\n",
    "for sample in train_samples:\n",
    "    pose_sequence = utils_for_students.load_sample_stage2(os.path.join('data/stage2/train/', sample['path']))\n",
    "    X_train.append(extract_features(pose_sequence))\n",
    "    y_train.append(sample['label'])\n",
    "    signers_train.append(sample['signer'])\n",
    "    \n",
    "# Concatenate the test set features.\n",
    "X_test = []\n",
    "test_ids = []\n",
    "for sample in test_samples:\n",
    "    pose_sequence = utils_for_students.load_sample_stage2(os.path.join('data/stage2/test/', sample['path']))\n",
    "    X_test.append(extract_features(pose_sequence))\n",
    "    test_ids.append(sample['id'])\n",
    "\n",
    "#Combining to numpy array\n",
    "X_train = np.stack(X_train)\n",
    "X_test = np.stack(X_test)\n",
    "\n",
    "# Encode the labels as integers\n",
    "label_encoder = utils_for_students.label_encoder()\n",
    "y_train = label_encoder.transform(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "175ce5c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01ba8924",
   "metadata": {},
   "source": [
    "## 4. Creating pipelines for preprocessing and feature selection \n",
    "\n",
    "Now, we are ready to define our pipelines. You can create the same pipeline as for stage 1 as a baseline, but you will be expected to tune both the feature engineering\n",
    "and pipeline parts of your model iteratively to improve your results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9bd45d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: define preprocessing pipeline here\n",
    "# It is up to you to define the number of modules in each pipeline and their types\n",
    "\n",
    "preprocessing = Pipeline([('<module_1_name>',None),('<module_2_name>',None)]) \n",
    "#TODO: define feature selection pipeline here\n",
    "feature_selection = Pipeline([('<module_3_name>',None),('<module_4_name>',None)]) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ea41917",
   "metadata": {},
   "source": [
    "## 5. Define a suitable classifier\n",
    "With your preprocessing and feature selection in place, it is now time to define the final element: a suitable classifier. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8a4112d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: define proper classifier\n",
    "classifier = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "419c4f62",
   "metadata": {},
   "source": [
    "## 6. Set up hyperparameter grid for [GridsearchCV](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html?highlight=gridsearchcv#sklearn.model_selection.GridSearchCV) object.\n",
    "\n",
    "Now, define your GridSearchCV hyperparameter grid and object.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63d28c4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "                'preprocessing__<module_1_name>__<hyperparam_1_name>' : [0],\n",
    "                'preprocessing__<module_1_name>__<hyperparam_2_name>' : [0],\n",
    "                'preprocessing__<module_2_name>__<hyperparam_1_name>' : [0],\n",
    "                'preprocessing__<module_2_name>__<hyperparam_2_name>' : [0],\n",
    "                'feature_selection__<module_1_name>__<hyperparam_1_name>' : [0],\n",
    "                'feature_selection__<module_1_name>__<hyperparam_2_name>' : [0],\n",
    "                'feature_selection__<module_2_name>__<hyperparam_1_name>' : [0],\n",
    "                'feature_selection__<module_2_name>__<hyperparam_2_name>' : [0],\n",
    "                'classifier__<hyperparam_1_name>' : [0],\n",
    "                'classifier__<hyperparam_2_name>' : [0]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13458f17",
   "metadata": {},
   "source": [
    "## 7. Define the number of crossvaldation folds and how to split\n",
    "\n",
    "Now, you should define the number of CV folds and how to split the data.\n",
    "Assuming you had a correct split in the first stage of the competition, you can re-use the same code.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5a21c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: set appropriate number of cv folds\n",
    "n_folds = None   \n",
    "\n",
    "# The function below is just an example!\n",
    "#TODO: write a better split function here?\n",
    "def create_folds(X,y,n_folds):\n",
    "    folds = []\n",
    "    cv_object = KFold(n_splits = n_folds)\n",
    "    for (train_indices, val_indices) in  cv_object.split(X_train, y_train):\n",
    "        folds.append((train_indices,val_indices))\n",
    "    return folds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "451f962b",
   "metadata": {},
   "source": [
    "## 8. Training the model\n",
    "Now it is time to put everything together and train the model. As you can see, `GridsearchCV` takes the pipelines as well as the classifier and the hyperparameter dictionary you defined, and uses `create_folds` to create list of train and test indices for each split. Then the model is trained using `cv.fit()` and the model and submission files are written to the file system.\n",
    "\n",
    "In stage 2, this cell is no longer locked and you are free to edit it as you like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed6610e9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('preprocessing', preprocessing),\n",
    "    ('feature_selection', feature_selection),\n",
    "    ('classifier', classifier)])\n",
    "\n",
    "folds = create_folds(X_train,y_train,n_folds)\n",
    "assert isinstance(folds,list),'Folds must be presented as tuples of train and test index lists' \n",
    "\n",
    "# train model\n",
    "cv = GridSearchCV(pipeline, param_grid, n_jobs=4, cv=folds, verbose=1, return_train_score=True, refit=True)\n",
    "cv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "018137ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write out model\n",
    "#make sure student data is filled in to give the file a speaking name\n",
    "assert student_id is not None and student_lastname is not None and student_firstname is not None, 'Please fill in your Name and Student Id'\n",
    "\n",
    "submission_dirname = 'submission'\n",
    "if use_timestamps:\n",
    "    timestamp = time.strftime(\"%Y%m%d-%H%M%S\", time.localtime())\n",
    "    filename_model = os.path.join(submission_dirname,f'stage2_model_{student_id}_{student_lastname}_{student_firstname}_{timestamp}.pkl')\n",
    "    filename_submission =  os.path.join(submission_dirname,f'stage2_{submission_prefix}_{student_id}_{student_lastname}_{student_firstname}_{timestamp}.csv')\n",
    "else:\n",
    "    filename_model = os.path.join(submission_dirname,f'stage2_model_{student_id}_{student_lastname}_{student_firstname}.pkl')\n",
    "    filename_submission =  os.path.join(submission_dirname,f'stage2_{submission_prefix}_{student_id}_{student_lastname}_{student_firstname}.csv')\n",
    "\n",
    "if not os.path.exists(submission_dirname):\n",
    "    os.mkdir(submission_dirname)    \n",
    "\n",
    "with open(filename_model,'wb') as file:\n",
    "    pickle.dump(cv,file)\n",
    "    \n",
    "prediction = label_encoder.inverse_transform(cv.best_estimator_.predict(X_test))\n",
    "utils_for_students.create_submission_file(filename_submission, test_ids, prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccbed0cd",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 9. Printing scores\n",
    "Here we simply extract a bit more information about the individual scores obtained by the classifers we trained to fit the individual folds. Maybe a few plots may be useful to better understand what your classifier is doing? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1363c99",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = cv.cv_results_\n",
    "mean_train_score = results['mean_train_score'][cv.best_index_]\n",
    "std_train_score = results['std_train_score'][cv.best_index_]\n",
    "mean_cv_score = results['mean_test_score'][cv.best_index_]\n",
    "std_cv_score = results['std_test_score'][cv.best_index_]\n",
    "\n",
    "print('Training accuracy {} +/- {}'.format(mean_train_score, std_train_score))\n",
    "print('Cross-validation accuracy: {} +/- {}'.format(mean_cv_score, std_cv_score))\n",
    "\n",
    "print('Best estimator:')\n",
    "print(cv.best_estimator_)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5b96519fadf0e27573d7db6a7c141d11ba6990cab00b556a7220b1bf1bdbac7f"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
